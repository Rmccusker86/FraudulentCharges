
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error,mean_absolute_error



regr=LinearRegression()
train=pd.read_csv("https://github.com/Rmccusker86/FraudulentCharges/blob/main/train_transaction.csv?raw=true")
# test=pd.read_csv("https://github.com/Rmccusker86/FraudulentCharges/blob/main/test_transaction.csv?raw=true")



# columns for creating unique ids
cols=[f"card{i}" for i in range(1,7)]+["addr1","addr2"]

# unique ids
train["user_id"]=train[cols].apply(lambda x:"_".join(x.values.astype(str)),axis=1)

# identifying user ids with fraudulent transactions
frauds=train.query("isFraud==1").user_id.unique()


# creating main dataframe
df=train[train.user_id.isin(frauds)]


# sorting by user id and transaction order
df.sort_values(by=["user_id","TransactionID"],inplace=True)

# df=df.sort_values(["user_id","TransactionID"]).groupby("user_id").tail(100)

# fix indices
df.reset_index(drop=True,inplace=True)


# getting number of total transactions and total fraudulent ones by user id
transaction_counts=df.groupby("user_id").agg(total_transactions=("TransactionID","nunique"),
                                             fraudulent_transaction=("isFraud","sum")).reset_index()
                                             
                                             
                                             
transaction_threshold=20
fraud_threshold=5
clean_head_threshold=4
dirty_tail_threshold=3


candidates=transaction_counts.query(f"total_transactions>={transaction_threshold} and fraudulent_transaction>={fraud_threshold}").user_id.unique()


df=df[df.user_id.isin(candidates)].merge(transaction_counts,on="user_id")

df.reset_index(drop=True,inplace=True)



df["fraud_pct"]=df.fraudulent_transaction/df.total_transactions




clean_heads=df.sort_values(["user_id","TransactionID"]).groupby("user_id").head(clean_head_threshold).groupby("user_id").isFraud.sum().reset_index().query(f"isFraud==0").user_id.unique()


dirty_tails=df.sort_values(["user_id","TransactionID"]).groupby("user_id").tail(transaction_threshold).groupby("user_id").isFraud.sum().reset_index().query(f"isFraud>={dirty_tail_threshold}").user_id.unique()

clean=df[(df.user_id.isin(clean_heads))&(df.user_id.isin(dirty_tails))]




clean["prev_is_fraud"]=clean.sort_values(["user_id","TransactionID"]).groupby("user_id").isFraud.shift()


clean["rolling_mean_6"]=clean.sort_values(["user_id","TransactionID"]).groupby("user_id").TransactionAmt.rolling(6).mean().reset_index(0,drop=True)

for i in range(1,3):
    clean[f"prev_transaction_{i}"]=clean.sort_values(["user_id","TransactionID"]).groupby("user_id").TransactionAmt.shift(i)


clean["prev_dt"]=clean.sort_values(["user_id","TransactionID"]).groupby("user_id").TransactionDT.shift()
clean["time_delta_from_last_transaction"]=clean.TransactionDT-clean.prev_dt



p_email_pct=clean.P_emaildomain.value_counts(normalize=True).cumsum().reset_index()
keep_p_mail=p_email_pct.query("P_emaildomain<=0.90")["index"].values.tolist()

r_email_pct=clean.R_emaildomain.value_counts(normalize=True).cumsum().reset_index()
keep_r_mail=r_email_pct.query("R_emaildomain<=0.90")["index"].values.tolist()


clean.loc[clean.P_emaildomain.isin(keep_p_mail)==False,"P_emaildomain"]="othermail.com"
clean.loc[clean.R_emaildomain.isin(keep_r_mail)==False,"R_emaildomain"]="othermail.com"


p_emails=pd.get_dummies(clean.P_emaildomain.fillna("Unknown"))
r_emails=pd.get_dummies(clean.R_emaildomain.fillna("Unknown"))


p_emails.columns=[f"p_{i}" for i in p_emails.columns]
r_emails.columns=[f"r_{i}" for i in r_emails.columns]


clean=pd.concat([clean,p_emails,r_emails],axis=1).reset_index(drop=True)

clean["y"]=clean.sort_values(["user_id","TransactionID"]).groupby("user_id").TransactionAmt.shift(-1)


cols=["rolling_mean_6","TransactionAmt","prev_is_fraud",
       "time_delta_from_last_transaction"]+[i for i in clean.columns if i.startswith("prev_transaction")]+p_emails.columns.tolist()+r_emails.columns.tolist()


clean.dropna(subset=cols+["y"],inplace=True)


clean=clean.query("isFraud==1")
clean.reset_index(drop=True,inplace=True)



clean["q"]=pd.qcut(clean.prev_transaction_1,6)


for q_ in clean.q.unique():
    temp=clean[clean["q"]==q_]

    X=temp[cols]
    y=temp["y"]
    regr.fit(X,y)
    print(q_,regr.score(X,y),mean_squared_error(y,regr.predict(X))**(1/2),mean_absolute_error(y,regr.predict(X)))
    