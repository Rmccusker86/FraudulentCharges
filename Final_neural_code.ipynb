{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitly require this experimental feature\n",
    "# from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "# now you can import normally from ensemble\n",
    "# from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import pandas as pd\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,confusion_matrix,roc_auc_score,ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "from tensorflow import keras\n",
    "from time import asctime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file\n"
     ]
    }
   ],
   "source": [
    "# logistic=MLPClassifier(hidden_layer_sizes=(256,256,128),max_iter=5,tol=1e-15,solver=\"adam\",verbose=True,warm_start=True,n_iter_no_change=1000,learning_rate=\"adaptive\")\n",
    "logistic=MLPClassifier(hidden_layer_sizes=(512,512,512,512,512),max_iter=10,tol=1e-15,solver=\"adam\",verbose=True,warm_start=True,n_iter_no_change=1000,learning_rate=\"adaptive\",early_stopping=True,validation_fraction=0.20)\n",
    "\n",
    "print(\"reading file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train_transaction.csv\")\n",
    "# train=pd.read_pickle(\"cc_fraud_train_set.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file read.\n"
     ]
    }
   ],
   "source": [
    "print(\"file read.\")\n",
    "# cols=[i for i in train.columns if i.startswith(\"M\") or i.startswith(\"D\")]\n",
    "df=train.copy()\n",
    "categoricals=df.select_dtypes(\"object\").columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixing categoricals\n"
     ]
    }
   ],
   "source": [
    "print(\"fixing categoricals\")\n",
    "for obj_col in categoricals:\n",
    "    temp=pd.get_dummies(df[obj_col])\n",
    "    temp.columns=[f\"{obj_col}_{col}\" for col in temp.columns.tolist()]\n",
    "    df=pd.concat([df.drop(columns=[obj_col]),temp],axis=1)\n",
    "df.drop(columns=[\"TransactionID\",\"TransactionDT\"],inplace=True)\n",
    "Xy=pd.DataFrame(df.values,columns=df.columns).drop(columns=[\"isFraud\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>C1</th>\n",
       "      <th>...</th>\n",
       "      <th>M5_F</th>\n",
       "      <th>M5_T</th>\n",
       "      <th>M6_F</th>\n",
       "      <th>M6_T</th>\n",
       "      <th>M7_F</th>\n",
       "      <th>M7_T</th>\n",
       "      <th>M8_F</th>\n",
       "      <th>M8_T</th>\n",
       "      <th>M9_F</th>\n",
       "      <th>M9_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.5</td>\n",
       "      <td>13926.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>2755.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.0</td>\n",
       "      <td>4663.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>18132.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>4497.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 528 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionAmt    card1  card2  card3  card5  addr1  addr2  dist1  dist2  \\\n",
       "0            68.5  13926.0    NaN  150.0  142.0  315.0   87.0   19.0    NaN   \n",
       "1            29.0   2755.0  404.0  150.0  102.0  325.0   87.0    NaN    NaN   \n",
       "2            59.0   4663.0  490.0  150.0  166.0  330.0   87.0  287.0    NaN   \n",
       "3            50.0  18132.0  567.0  150.0  117.0  476.0   87.0    NaN    NaN   \n",
       "4            50.0   4497.0  514.0  150.0  102.0  420.0   87.0    NaN    NaN   \n",
       "\n",
       "    C1  ...  M5_F  M5_T  M6_F  M6_T  M7_F  M7_T  M8_F  M8_T  M9_F  M9_T  \n",
       "0  1.0  ...   1.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1  1.0  ...   0.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2  1.0  ...   1.0   0.0   1.0   0.0   1.0   0.0   1.0   0.0   1.0   0.0  \n",
       "3  2.0  ...   0.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4  1.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 528 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating validation set\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "Xy[\"fraud\"]=train.isFraud.copy()\n",
    "print(\"creating validation set\")\n",
    "validate=Xy.sample(frac=0.20) # data completely unseen\n",
    "Xy=Xy[Xy.index.isin(validate.index)==False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones=ones=1/Xy.fraud.sum()\n",
    "zeros=1/len(np.where(Xy.fraud==0)[0])\n",
    "class_weights={0:zeros,1:ones}\n",
    "rf=RandomForestClassifier(class_weight=class_weights)\n",
    "sample=Xy.sample(frac=1)#was 0.20\n",
    "sample_X=scaler.fit_transform(sample.drop(columns=\"fraud\").fillna(0).values)\n",
    "sample_X_df=pd.DataFrame(sample_X,columns=Xy.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reducing float64s to round 8\n"
     ]
    }
   ],
   "source": [
    "print(\"reducing float64s to round 8\")\n",
    "sample_X=np.round(sample_X,8)        \n",
    "sample_y=sample.fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting correlations\n",
      "Wed Feb 16 20:00:48 2022\n"
     ]
    }
   ],
   "source": [
    "print(\"getting correlations\")\n",
    "# corrs=pd.DataFrame(sample_X,columns=Xy.columns[:-1]).corr()\n",
    "corrs=pd.DataFrame(Xy.drop(columns=\"fraud\"),columns=Xy.columns[:-1]).corr()\n",
    "print(asctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting importances\n",
      "Wed Feb 16 20:04:59 2022\n"
     ]
    }
   ],
   "source": [
    "print(\"getting importances\")\n",
    "corrs_stack=corrs.index.tolist()\n",
    "importances=pd.DataFrame(rf.fit(sample_X_df[corrs_stack],sample_y).feature_importances_.reshape(1,-1),columns=corrs_stack).T.reset_index().values.tolist()\n",
    "print(asctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting highly correlated fields\n",
      "523\n",
      "518\n",
      "444\n",
      "444\n",
      "444\n",
      "444\n",
      "444\n",
      "444\n",
      "444\n",
      "444\n",
      "444\n",
      "441\n",
      "441\n",
      "441\n",
      "441\n",
      "441\n",
      "441\n",
      "433\n",
      "430\n",
      "430\n",
      "429\n",
      "427\n",
      "415\n",
      "403\n",
      "403\n",
      "397\n",
      "394\n",
      "390\n",
      "390\n",
      "388\n",
      "388\n",
      "388\n",
      "387\n",
      "387\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "382\n",
      "382\n",
      "382\n",
      "382\n",
      "382\n",
      "382\n",
      "382\n",
      "382\n",
      "382\n",
      "382\n",
      "382\n",
      "364\n",
      "363\n",
      "360\n",
      "360\n",
      "360\n",
      "360\n",
      "359\n",
      "356\n",
      "355\n",
      "355\n",
      "353\n",
      "352\n",
      "344\n",
      "338\n",
      "338\n",
      "338\n",
      "338\n",
      "338\n",
      "338\n",
      "335\n",
      "335\n",
      "324\n",
      "324\n",
      "323\n",
      "323\n",
      "323\n",
      "316\n",
      "316\n",
      "315\n",
      "310\n",
      "305\n",
      "305\n",
      "305\n",
      "305\n",
      "305\n",
      "305\n",
      "305\n",
      "305\n",
      "305\n",
      "303\n",
      "303\n",
      "302\n",
      "302\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "300\n",
      "300\n",
      "300\n",
      "298\n",
      "298\n",
      "298\n",
      "298\n",
      "298\n",
      "298\n",
      "298\n",
      "298\n",
      "296\n",
      "296\n",
      "296\n",
      "296\n",
      "295\n",
      "295\n",
      "295\n",
      "295\n",
      "294\n",
      "285\n"
     ]
    }
   ],
   "source": [
    "corrs_stack=[i[0] for i in sorted(importances,key=lambda x:x[1],reverse=True) if i[1]!=0]\n",
    "print(\"getting highly correlated fields\")\n",
    "\n",
    "for i in corrs_stack:\n",
    "    test=corrs.loc[i].reset_index()\n",
    "    test=test[abs(test[i])>0.80]\n",
    "    if len(test[test[\"index\"]!=i])>0:\n",
    "        for r in test[test[\"index\"]!=i][\"index\"].unique().tolist():\n",
    "            try:\n",
    "                corrs_stack.remove(r)\n",
    "            except:\n",
    "                print(len(corrs_stack))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[corrs_stack]\n",
    "Xy=Xy[corrs_stack+[\"fraud\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_stack=[]\n",
    "val_auc_stack=[]\n",
    "# scaler.fit(Xy[re_importances.field.values])\n",
    "scaler.fit(Xy[corrs_stack])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=pd.DataFrame(scaler.transform(Xy[re_importances.field.values].fillna(0)),columns=Xy.columns[:-1])\n",
    "X=pd.DataFrame(scaler.transform(Xy[corrs_stack].fillna(0)),columns=Xy.columns[:-1])\n",
    "y=Xy.fraud.reset_index(drop=True)\n",
    "# X_test=scaler.transform(validate[re_importances.field.values].fillna(0))\n",
    "X_test=pd.DataFrame(scaler.transform(validate[corrs_stack].fillna(0)),columns=corrs_stack)\n",
    "y_test=validate.fraud\n",
    "X=np.round(X,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic=MLPClassifier(hidden_layer_sizes=(256,256,256),max_iter=10,tol=1e-15,solver=\"adam\",learning_rate_init=0.001,verbose=True,warm_start=True,n_iter_no_change=1000,learning_rate=\"adaptive\")#,early_stopping=True,validation_fraction=0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n"
     ]
    }
   ],
   "source": [
    "choices=[21,51,61,81,101]\n",
    "p=[0.20,0.30,0.20,0.25,0.05]\n",
    "auc_val_stack=[]\n",
    "# !!!! set params accordingly\n",
    "print(\"starting training\")\n",
    "choice=np.random.choice(choices,p=p)\n",
    "sample_pct=1.0#np.random.randint(10,choice)/100\n",
    "y_train=y.sample(frac=sample_pct)\n",
    "X_train=X.loc[y_train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               68864     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200,705\n",
      "Trainable params: 200,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            256, activation=\"relu\", input_shape=(X_train.shape[-1],)\n",
    "        ),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    # keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.AUC(name=\"auc\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_auc', patience=200),keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}_val_scores_tp_{val_tp}_fn_{val_fn}_tn_{val_tn}_fp_{val_fp}_auc_{val_auc}.h5\")]\n",
    "class_weight = class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25ea2a051c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train.values,\n",
    "    y_train.values,\n",
    "    batch_size=2048,\n",
    "    epochs=200,\n",
    "    verbose=0,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_test.values, y_test.values),\n",
    "    class_weight=class_weight,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e57720c8aab2e56f57690a4fcd79250b09ae91306a874c9c69144a6a9cbce83"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
